(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{517:function(v,_,a){"use strict";a.r(_);var t=a(6),e=Object(t.a)({},(function(){var v=this,_=v.$createElement,a=v._self._c||_;return a("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"title"}),a("p",[v._v("理论知识点：\n存储模型\n架构设计\n角色功能\n元数据持久化\n安全模式\n副本放置策略\n读写流程\n安全策略")])]),a("h1",{attrs:{id:"存储模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#存储模型"}},[v._v("#")]),v._v(" 存储模型")]),v._v(" "),a("p",[v._v("文件线性按字节切割成块（block），具有offset，id；")]),v._v(" "),a("p",[v._v("文件与文件的block大小可以不一样；")]),v._v(" "),a("p",[v._v("一个文件除最后一个block，其他block大小一致；")]),v._v(" "),a("p",[v._v("block的大小依据硬件的I/O特性调整；")]),v._v(" "),a("p",[v._v("block被分散存放在集群的节点中，具有location；")]),v._v(" "),a("p",[v._v("block具有副本（replication），没有主从概念，副本不能出现在同一个节点；")]),v._v(" "),a("p",[v._v("副本是满足可靠性和性能的关键；")]),v._v(" "),a("p",[v._v("文件上传可以指定block大小和副本数，上传后只能修改副本数；")]),v._v(" "),a("p",[v._v("一次写入多次读取，不支持修改；")]),v._v(" "),a("p",[v._v("支持追加数据；")]),v._v(" "),a("h1",{attrs:{id:"架构设计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#架构设计"}},[v._v("#")]),v._v(" 架构设计")]),v._v(" "),a("p",[v._v("HDFS是一个主从（Master/Slaves）架构")]),v._v(" "),a("p",[v._v("由一个NameNode和一些DataNode组成")]),v._v(" "),a("p",[v._v("面向文件包含：文件数据（data）和文件元数据（metadata）")]),v._v(" "),a("p",[v._v("NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树")]),v._v(" "),a("p",[v._v("DataNode负责存储文件数据（block块），并提供block的读写")]),v._v(" "),a("p",[v._v("DataNode与NameNode维持心跳，并汇报自己持有的block信息")]),v._v(" "),a("p",[v._v("Client和NameNode交互文件元数据和DataNode交互文件block数据")]),v._v(" "),a("h1",{attrs:{id:"角色功能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#角色功能"}},[v._v("#")]),v._v(" 角色功能")]),v._v(" "),a("h2",{attrs:{id:"namenode"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#namenode"}},[v._v("#")]),v._v(" NameNode")]),v._v(" "),a("p",[v._v("完全基于内存存储文件元数据、目录结构、文件block的映射")]),v._v(" "),a("p",[v._v("需要持久化方案保证数据可靠性")]),v._v(" "),a("p",[v._v("提供副本放置策略")]),v._v(" "),a("h2",{attrs:{id:"datanode"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#datanode"}},[v._v("#")]),v._v(" DataNode")]),v._v(" "),a("p",[v._v("基于本地磁盘存储block（文件的形式）")]),v._v(" "),a("p",[v._v("并保存block的校验和数据保证block的可靠性")]),v._v(" "),a("p",[v._v("与NameNode保持心跳，汇报block列表状态")]),v._v(" "),a("h1",{attrs:{id:"元数据持久化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#元数据持久化"}},[v._v("#")]),v._v(" 元数据持久化")]),v._v(" "),a("p",[v._v("任何对文件系统元数据产生修改的操作，NameNode都会使用一张称为EditLog的事务日志记录下来")]),v._v(" "),a("p",[v._v("使用F是Image存储内存所有的元数据状态")]),v._v(" "),a("p",[v._v("使用本地磁盘保存EditLog和FsImage")]),v._v(" "),a("p",[v._v("EditLog具有完整性，数据丢失少，但恢复速度慢，并有体积膨胀风险")]),v._v(" "),a("p",[v._v("FsImage具有恢复速度快，体积与内存数据相当，但不能实时保存，数据丢失多")]),v._v(" "),a("p",[v._v("NameNode使用了FsImage+EditLog整合的方案：滚动将增量的EditLog更新到F是Image，以保证更近时点的FsImage和更小的EditLog体积")]),v._v(" "),a("h1",{attrs:{id:"安全模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安全模式"}},[v._v("#")]),v._v(" 安全模式")]),v._v(" "),a("p",[v._v("HDFS搭建时会格式化，格式化操作会产生一个空的FsImage")]),v._v(" "),a("p",[v._v("当NameNode启动时，它从硬盘中读取EditLog和FsImage")]),v._v(" "),a("p",[v._v("将所有EditLog中的事务作用在内存中的FsImage上")]),v._v(" "),a("p",[v._v("并将这个新版本的FsImage从内存中保存到本地磁盘上")]),v._v(" "),a("p",[v._v("然后删除旧的EditLog，因为这个旧的EditLog的事务都已经作用在FsImage上了")]),v._v(" "),a("h1",{attrs:{id:"hdfs中的snn"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hdfs中的snn"}},[v._v("#")]),v._v(" HDFS中的SNN")]),v._v(" "),a("p",[v._v("SecondaryNameNode（SNN）")]),v._v(" "),a("p",[v._v("在非Ha模式下，SNN一般都是独立的节点，周期完成对NN的EditLog向FsImage合并，减少EditLog大小，减少NN启动时间")]),v._v(" "),a("p",[v._v("根据配置文件设置的时间间隔fs.checkpoint.period默认3600秒")]),v._v(" "),a("p",[v._v("根据配置文件设置edits log大小fs.checkponint.size规定edits文件的最大值默认是64MB")]),v._v(" "),a("h1",{attrs:{id:"block的副本防止策略"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#block的副本防止策略"}},[v._v("#")]),v._v(" Block的副本防止策略")]),v._v(" "),a("p",[v._v("第一副本：防止在上传文件的DN；如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点、。")]),v._v(" "),a("p",[v._v("第二个副本：放置在于第一个副本不同的机架的节点上。")]),v._v(" "),a("p",[v._v("第三个副本：与第二个副本相同机架的节点。")]),v._v(" "),a("p",[v._v("更多副本：随机节点。")]),v._v(" "),a("h1",{attrs:{id:"hdfs写流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hdfs写流程"}},[v._v("#")]),v._v(" HDFS写流程")]),v._v(" "),a("p",[v._v("Client和NN连接创建文件元数据。")]),v._v(" "),a("p",[v._v("NN判定元数据是否有效")]),v._v(" "),a("p",[v._v("NN处发副本放置策略，返回一个有序的DN列表")]),v._v(" "),a("p",[v._v("Client和DN建立Pipeline连接")]),v._v(" "),a("p",[v._v("Client将块切分成packet（64KB），并使用chunk（512B）+chucksum（4B）填充")]),v._v(" "),a("p",[v._v("Client将packet放入发送队列dataqueue中，并向第一个DN发送")]),v._v(" "),a("p",[v._v("第一个DN收到packet后本地保存并发送给第二个DN")]),v._v(" "),a("p",[v._v("第二个DN收到packet后本地保存并发送给第三个DN")]),v._v(" "),a("p",[v._v("这一个过程总，上游节点同时发送下一个packet")]),v._v(" "),a("p",[v._v("HDFS使用这种传输方式，副本数对于client是透明的")]),v._v(" "),a("p",[v._v("当block传输完成，DN们各自向NN汇报，同时client继续传输下一个block")]),v._v(" "),a("p",[v._v("所以，client的传输和block的汇报也是并行的")])])}),[],!1,null,null,null);_.default=e.exports}}]);